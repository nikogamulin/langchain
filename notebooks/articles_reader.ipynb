{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "import openai\n",
    "from tqdm import tqdm\n",
    "import gspread\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your OpenAI API key\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "def list_pdf_files(folder_path):\n",
    "    pdf_files = [file for file in os.listdir(folder_path) if file.endswith('.pdf')]\n",
    "    return pdf_files\n",
    "\n",
    "def read_pdf(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "        text = ''\n",
    "        for page_num in range(len(pdf_reader.pages)):\n",
    "            text += pdf_reader.pages[page_num].extract_text()\n",
    "            # assume the abstract is on the first page\n",
    "            break\n",
    "    return text\n",
    "\n",
    "def extract_abstract(text):\n",
    "    messages = [\n",
    "    {\"role\": \"system\", \"content\" : \"You’re a kind helpful assistant for extracting the title and the abstract from the first page of scientific article\"}\n",
    "    ]\n",
    "    messages.append(\n",
    "        {\"role\": \"user\", \"content\": f\"extract the title and theabstract from the following content. The content is the first page of read pdf. It contains the title at the top and after the abstract, it contains most likely keywords and introduction chapter return the result in json format with properties title and abstract. Content: {text}\"}\n",
    "    )\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages\n",
    "    )\n",
    "    chat_response = completion.choices[0].message.content\n",
    "    return chat_response\n",
    "\n",
    "folder_path = \"../articles\"\n",
    "\n",
    "pdf_files = list_pdf_files(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_files = {}\n",
    "errors = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 61/172 [15:01<16:14,  8.78s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing 2002 Maly et al - Seasonal variability in soil N mineralization and nitrification as influenced by N fertilization.pdf: This model's maximum context length is 4097 tokens. However, your messages resulted in 11501 tokens. Please reduce the length of the messages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 88/172 [20:43<14:11, 10.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing 2008 Nakhone and Tabatabai - Nitrogen mineralization of leguminous crops in soils.pdf: This model's maximum context length is 4097 tokens. However, your messages resulted in 8997 tokens. Please reduce the length of the messages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 109/172 [25:15<12:16, 11.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing 2003 Paul et al - Defining the relation between soil water content and net nitrogen mineralization.pdf: This model's maximum context length is 4097 tokens. However, your messages resulted in 7688 tokens. Please reduce the length of the messages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 172/172 [39:50<00:00, 13.90s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with tqdm(total=len(pdf_files)) as pbar:\n",
    "    for pdf_file in pdf_files:\n",
    "        if pdf_file in processed_files:\n",
    "            pbar.update(1)\n",
    "            continue\n",
    "        try:\n",
    "            file_path = os.path.join(folder_path, pdf_file)\n",
    "            text = read_pdf(file_path)\n",
    "            # print(text)\n",
    "            parsed_content = extract_abstract(text)\n",
    "            processed_files[pdf_file] = parsed_content\n",
    "            # print(f\"Abstract for {pdf_file}:\\n{parsed_content}\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {pdf_file}: {e}\")\n",
    "            errors[pdf_file] = e\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Pea green manure management affects organic winter wheat yield and quality in semiarid Montana',\n",
       " 'abstract': 'Organic farmers in semiarid Montana desire green manures that supply sufficient soil nitrate-N (NO 3-N) to subsequent crops with minimal soil water depletion. Spring and winter pea (Pisum sativum L.) green manures were compared at the bloom and pod stages for soil NO 3-N contribution and water use, and subsequent winter wheat (Triticum aestivum L.) grain yield and quality in a long-term organic farm in northern Montana.'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(processed_files['2011 Miller et al - Pea green manure management affects organic winter wheat yield and quality in semiarid Montana.pdf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_files\n",
    "items_list = []\n",
    "failed_items = []\n",
    "for key, value in processed_files.items():\n",
    "    try:\n",
    "        # Remove newlines\n",
    "        value = re.sub('\\n', '', value)\n",
    "\n",
    "        # Replace multiple spaces with single space\n",
    "        value = re.sub(' +', ' ', value)\n",
    "\n",
    "        # Remove trailing comma (if present)\n",
    "        value = re.sub(',\\s*}', '}', value)\n",
    "\n",
    "        # Remove single quotes and double quotes within double quotes\n",
    "        value = re.sub('(\".*?)\"', lambda x: x.group(1).replace(\"'\", \"\").replace('\"', ''), value)\n",
    "\n",
    "        # print(value)\n",
    "        if '\"title\"' not in value:\n",
    "            title, abstract = value.split('abstract:')\n",
    "            title = title.replace('title:', '')\n",
    "            # remove curly braces\n",
    "            title = title.replace('{', '').replace('}', '')\n",
    "            abstract = abstract.replace('{', '').replace('}', '')\n",
    "            # remove leading and trailing spaces\n",
    "            title = title.strip()\n",
    "            abstract = abstract.strip()\n",
    "            #remove leading and trailing commas\n",
    "            title = title.strip(',')\n",
    "            abstract = abstract.strip(',')\n",
    "            # json_object = {\"title\": title, \"abstract\": abstract}\n",
    "        else:\n",
    "            json_object = json.loads(value)\n",
    "            title = json_object['title']\n",
    "            abstract = json_object['abstract']\n",
    "        # json_object['file_name'] = key\n",
    "        items_list.append([key, title, abstract])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(value)\n",
    "        failed_items.append(value)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# items_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe from dictionary\n",
    "df = df = pd.DataFrame(items_list, columns=['filename', 'title', 'abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframe to CSV file\n",
    "df.to_csv('my_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['abstract'] = df['abstract'].apply(lambda x: x.lower())\n",
    "df['abstract_modified'] = df['abstract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "auto-gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "53eb487545d1ed174505cf4905d10dfe91dbcf567100ade37908d6d565013ec9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
